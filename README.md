# Uma rede neural para aproximar a fun√ß√£o seno sem uso de bibliotecas externas
Esse projeto faz parte da pesquisa da Inicia√ß√£o Cient√≠fica do LIPAI-Inicia√ß√£o Cient√≠fica e Trabalho de Conclus√£o ofertada na UFU. Aqui vou buscar criar e explicar a cria√ß√£o e l√≥gica de uma rede neural simples, o objetivo √© n√£o usar bibliotecas que simplifiquem demais e abstraiam do programador o funcionamento real das redes neurais como PyTorch e TensorFlow.
Ser√£o usadas bibliotecas de c√°lculos como a NumPy para calculos de multiplica√ß√µes de matrizes e senos, bibliotecas como matplotlib ser√£o usadas para cria√ß√£o de gr√°fcos que v√£o auxiliar no entendimento dos processos.

## L√≥gica geral
Antes de tudo a rede neural √© uma fun√ß√£o que recebe um apanhado de entradas e gera outro de sa√≠da. No exemplo desse notebook a fun√ß√£o seno recebe uma entrada x e uma sa√≠da y, assim ser√° a rede neural, receber√° um valor e dever√° responder com outro que, esperamos, seja o mais pr√≥ximo poss√≠vel da resposta correta.

### Neur√¥nios
S√£o as m√≠nimas partes fundamentais de uma rede neural, similarmente ao cerebro humano 
operam logicamente, a jun√ß√£o do trabalho de v√°rios culmina em uma rede neural. √â poss√≠vel
pensar que eles s√£o apenas bolas que gardam pesos. Esse √© uma imagem que pode ajudar a visualizar como cada neuronio se conecta com todos da camada anterior:

![imagem de uma rede neural simples](imagens/exemplo_rede_neural.jpeg)

Os neur√¥nios ficam separados em 3 camadas (ou, do ingl√™s, layers), os de entrada, intermedi√°rios (ou escondidos), e os de sa√≠da. Os intermedi√°rios tamb√©m podem ser chamados de escondidos, isso porque n√£o s√£o a parte interessante para o usu√°rio da rede;para quem a usa o importante √© a camda de entrada, que recebe os dados do usu√°rio e a desa√≠da que responde a informa√ß√£o pronta, a camada intermedi√°ria √©, para os usu√°rios uma caixa preta.

Redes podem possuir diversos neur√¥nios de entrada( como uma rede que interpreta imagens, cada pixel vai ser representado por um neur√¥nio na camada inicial) ou apenas um, como √© o caso dessa rede, ela recebe apenas um valor no eixo das abscisas.
A camada intermedi√°ria √© quem de fato "aprende" e prediz resultados, por causa disso possui v√°rios neur√¥nios e pode possuir v√°rias camadas dentro de s√≠. No exemplo daqui camda intermedi√°ria tem apenas uma _fileira_ de 20 neur√¥nios.

A camada de sa√≠da tamb√©m pode possuir diverssos neur√¥nios como em um caso em que predizse uma imagem √© a letra A ou E ou I ..., se h√° m√∫ltipla escolha pode haver v√°rios na sa√≠da. Se a resposta da rede deve ser SIM ou N√ÉO pode haver apenas um neur√¥nio e seu valor indicar, 0 como falso e 1 como verdadeiro. Aqui h√° apenas um neur√¥nio, seu valor √© a resposta da rede, como a fun√ß√£o seno possui imagem no intervalo [-1,1] esses s√£o os valores que o neur√¥nio pode ter.

---

### Ideia geral
√â esperado que a rede desse projeto receba um valor, o processe e retorne o seno dessa entrada, mas como isso √© poss√≠vel ? Em resumo, a rede neural inicia com neur√¥nios com pesos aleat√≥rios, a entrada  interage com esses pesos na camada interna e esses valores s√£o somados na camada de sa√≠da, esse valor √© a resposta que a rede tem a nos oferecer. 
Como na imagem:

![imagem de uma rede neural com pesos](imagens/rede_neural_pesos.png)

A gente pode considerar que o peso do neuronio de cima √© W1=0.5 , assim, 1 * 0.5 = 0.5 que √©o valor mostrado, o peso do segundo neur√¥nio √© W2=0.7 e ele tamb√©m possui um bias (um valor extra a ser somado) b2=1, assim 1*0.7 + 1 = 1.7, o mesmo para o neuronio de baixo: w3=3.4 e b3=1.7. O neuronio de sa√≠da temb√©m possui pesos e bias. √â importante entender que os pesos "est√£o nas conex√µes" entre neuronios e o bias √© do neuronio, isso √©, entre o neuoronio final e cada um dos 3 neuronios intermedi√°rios h√° um peso √∫nico, ou seja, 3 pesos, mas o bias √© unico para o neuronio final. Uma possibilidade √© que a configura√ß√£o seja:
0.5 * 0.4 - 0.9 = -0.7
1.7 * 0.4 - 0.9 = -1.22
5.1 * 0 - 0.9 = -0.9
O valor do ultimo neuronio vai ser a soma: -2.82

![imagem de uma rede neural com pesos](imagens/rede_neural_pesos_final.png)

√â √≥bvio que o seno de 1 n√£o √© -2.82 ent√£o precisamos decidir o qu√£o errada foi essa resposta e achar uma maneira de acertar os pesos e bias para que na pr√≥xima tentativa a rede melhore.

---

### Backpropagation
Depois que a rede faz a previs√£o e calculamos o qu√£o errada ela est√° (pela Fun√ß√£o de Perda que podem ser de v√°rios tipos, mas o objetivo √© sempre determinar o qu√£o errada foi a resposta da rede), precisamos ajustar os pesos para que, na pr√≥xima tentativa, o erro seja menor. Esse processo de ajuste √© o que chamamos de Backpropagation.

O objetivo √© minimizar a perda ajustando os pesos da rede. Para isso usamos o **Gradiente Descendente**.
Grdiente Descendente √© nada mais √© que aplicar derivada nessa Fun√ß√£o de Perda, a deivada √©  a reta tangente √† curva num determinado ponto, essa reta aponta para a dire√ß√£o de maior crescimento da fun√ß√£o, se formos na dire√ß√£o oposta entamos indo na dire√ß√£o que o erro √© o menos poss√≠vel. E exatamente isso o que queremos! Se vamos nessa dire√ß√£o, achamos como devemos mexer nos parametros da fun√ß√£o para diminuir o erro. Como os paramentros dessa fun√ß√£o s√£o o resultado otido pela rede e o resultado real podemos usar isso para determinar como os pesos devem mudar.
Assim podemos encontra a dire√ß√£o que mais rapidamente reduz a fun√ß√£o de perda. Imagine a fun√ß√£o de perda como um gr√°fico: a derivada no ponto atual mostra a dire√ß√£o de maior crescimento, ent√£o seguimos na dire√ß√£o contr√°ria, onde ela diminui.

A regra geral de ajuste do peso √©:

$$ z_j^L = Œ£_k (w_jk^L * a_k^(L-1)) + b_j^L $$


Onde:  
1. ` z_j^L`  √© a **entrada ponderada** do neur√¥nio `j` na camada `L`.  
2. `w_jk^L` √© o **peso** que conecta o neur√¥nio `k` da camada `L-1` ao neur√¥nio `j` da camada `L`.  
3. `a_k^(L-1)` √© a **ativa√ß√£o** do neur√¥nio `k` da camada anterior.  
4. `b_j^L` √© o **bias** do neur√¥nio `j`.

- Essa l√≥gica √© v√°lida para todas as camadas exceto a primeira, j√° que sua ativa√ß√£o √© definida diretamente pelo dado de entrada.
- A **ativa√ß√£o** do neur√¥nio √© definida apenas depois de passar pela **fun√ß√£o de ativa√ß√£o** como sigmoid ou ReLU.
- Passamos a entrada ponderada para a ativa√ß√£o para produzir **n√£o-linearidade**. Quebras de l√≥gica lineares consecutivas conseguem gerar resultados mais complexos do que uma √∫nica fun√ß√£o linear.

---

### Forward Pass

- A entrada de cada neur√¥nio na camada de input √© o valor da entrada; n√£o h√° ativa√ß√£o, entrada ponderada, pesos nem bias.
- Cada neur√¥nio da pr√≥xima camada aplica o c√°lculo da entrada ponderada e assim sucessivamente, at√© a √∫ltima camada de output.

---

### Loss Function

- Ap√≥s a √∫ltima camada ter calculado suas ativa√ß√µes, √© calculada uma **fun√ß√£o de perda** que mede o qu√£o errada foi a previs√£o.
- Pode ser, por exemplo, o **Erro Quadr√°tico M√©dio** ou **Cross-Entropy**.
- Chamamos de `L` essa fun√ß√£o.

---

### Backpropagation

- O objetivo √© minimizar a perda ajustando os pesos.
- Utiliza-se o **Gradiente Descendente** para encontrar a dire√ß√£o que reduz a fun√ß√£o de perda.
- √â como visualizar essa fun√ß√£o de perda em um gr√°fico e olhar a derivada no ponto que a camada de output nos deu, seguindo na dire√ß√£o negativa, em dire√ß√£o a um m√≠nimo local.
- A regra geral para o ajuste do peso √©: 
$$ w_jk^L = w_jk^L - n * (‚àÇL/‚àÇw_jk^L) $$


Onde:  
1. `w_jk^L` √© o peso que conecta o neur√¥nio `k` da camada `L-1` ao neur√¥nio `j` da camada `L`.  
2. `n` √© a **taxa de aprendizagem**.  
3. `‚àÇL/‚àÇw_jk^L` √© a **derivada da perda** em rela√ß√£o ao peso.

- Essa taxa de aprendizagem define o tamanho do passo:  
  - Passos grandes podem acelerar o processo mas podem saltar o m√≠nimo.  
  - Passos pequenos podem exigir milhares de itera√ß√µes para alcan√ßar um bom resultado.

---

### Como calcular essa derivada?

- Utiliza-se a **Regra da Cadeia** do c√°lculo diferencial, decompondo a derivada em partes.

$$ ‚àÇL/‚àÇw_jk^L = (‚àÇL/‚àÇa_j^L) * (‚àÇa_j^L/‚àÇz_j^L) * (‚àÇz_j^L/‚àÇw_jk^L) $$


- O que queremos aqui √© saber o quanto o peso influencia na fun√ß√£o de perda.
- Se a influ√™ncia for pequena, o "passo" deve ser maior; se for grande, os passos devem ser mais cautelosos.
- O problema √© que a fun√ß√£o de perda n√£o depende diretamente do peso.
- O caminho √©:  
  **Peso ‚Üí Entrada ponderada ‚Üí Ativa√ß√£o ‚Üí Sa√≠da da rede ‚Üí Perda**

---

### Primeiro termo: $$ ‚àÇL/‚àÇa_j^L $$


- Representa o **erro local**, ou seja, o quanto o neur√¥nio `j` da camada `L` influencia na perda.

---

### Segundo termo: $$ ‚àÇz_j^L/‚àÇw_jk^L $$


- √â a influ√™ncia direta do peso `w_jk` na entrada ponderada `z_j`.

- O produto desses dois termos mostra o quanto a ativa√ß√£o do neur√¥nio da camada anterior afeta a perda, mediado pelo erro local.

- Se a ativa√ß√£o `a_k^(L-1)` for alta e o erro local `Œ¥_j^L` tamb√©m, o peso associado a essa conex√£o deve ser fortemente ajustado.

---

### Como calcular o delta (`Œ¥`)?

- Seu c√°lculo √© diferente para as camadas **externa** e **internas**.



#### Na camada de sa√≠da: $$ Œ¥_j^L = ‚àÇL/‚àÇa_j^L * ‚àÇa_j^L/‚àÇz_j^L $$


- Queremos a derivada da **Fun√ß√£o de Perda** em rela√ß√£o √† **Entrada Ponderada**.
- Como a perda depende da sa√≠da, usamos novamente a **Regra da Cadeia**.


#### Nas camadas intermedi√°rias:

- Como n√£o h√° o erro direto, precisamos propagar o erro da camada de sa√≠da at√© ela.

$$ Œ¥_j^L = Œ£_m (Œ¥_m^(L+1) * w_mj^(L+1)) * ‚àÇa_j^L/‚àÇz_j^L $$


Onde:  
1. Pegamos os erros locais `Œ¥` de todos os neur√¥nios que foram afetados pelo atual na camada seguinte.  
2. Multiplicamos pelo peso que conecta o neur√¥nio atual com os da pr√≥xima camada.  
3. Somamos tudo, e esse √© o **erro retornado** pelo neur√¥nio atual.  
4. Multiplicamos pela derivada da fun√ß√£o de ativa√ß√£o do neur√¥nio atual.

---

## Resumo

- O **Backpropagation** √© a t√©cnica de calcular o erro e ajustar os pesos "de tr√°s para frente" na rede, camada a camada.
- A **Regra da Cadeia** permite decompor o c√°lculo da derivada da perda em rela√ß√£o aos pesos.
- O ajuste dos pesos √© guiado pela combina√ß√£o da ativa√ß√£o da camada anterior e do erro local propagado.


## O c√≥digo

#### Imports
``` python
    import numpy as np
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    import plotly.graph_objects as go
```
numpy √© usada para contas matem√°ticas como a de seno, tangente hiperb√≥lica, m√©dia, n√∫meros aleat√≥rios e etc. As demais s√£o apenas para visualiza√ß√µes, montar gr√°ficos que auxiliam no entendimento.

---

#### Primeiras defini√ß√µes
``` python
    def tanh(x):
    return np.tanh(x)

    def tanh_derivate(x):
    return 1 - np.tanh(x)**2

    def loss_fn(y_pred, y_true):
    return np.mean((y_pred - y_true)**2)

    def d_loss_y_pred(y_pred, y_true):
    return 2 * (y_pred - y_true) / y_true.size
```
Aqui definimos a fun√ß√£o de ativa√ß√£o, tanh, a tangente hiperb√≥lica, como o prop√≥sito aqui gira em torno de valores entre -1 e 1 essa ativa√ß√£o faz total sentido! Definimos tamb√©m sua derivada que vai ser usada nos c√°lculos do backpropagation. A fun√ß√£o de perda √© a m√©dia quadr√°tica entre o y predito pela rede e o y ideal que √© calculado realmente com a fun√ß√£o seno. Sua derivada em rela√ß√£o a y_pred tamb√©m√© usada no backpropagation.

--- 

#### Inicializa√ß√£o dos Pesos
```python
    np.random.seed(42)

    # Pesos entre camada de input e a oculta -> W1
    # Inicializa√ß√£o aleat√≥ria simples
    W1 = np.random.randn(1,10) * 0.1
    b1 = np.zeros((1,10))

    # Pesos entre camada de oculta e a sa√≠da -> W2
    W2 = np.random.randn(10,1) * 0.1
    b2 = np.zeros((1,1))
``` 
Inicialmente, usamos uma inicializa√ß√£o aleat√≥ria padr√£o, multiplicando os pesos por 0.1 para evitar valores grandes que podem saturar a tangente hiperb√≥lica (tanh). No entanto, vimos que essa abordagem pode exigir um n√∫mero excessivo de √©pocas para converg√™ncia.

``` python
    # T√©cnica de Xavier/Glorot Initialization for tanh
    n_in_W1 = 1
    n_out_W1 = 20
    std_dev_W1 = np.sqrt(2 / (n_in_W1 + n_out_W1))
    W1 = np.random.randn(n_in_W1, n_out_W1) * std_dev_W1
    b1 = np.zeros((1, n_out_W1))

    n_in_W2 = 20
    n_out_W2 = 1
    std_dev_W2 = np.sqrt(2 / (n_in_W2 + n_out_W2))
    W2 = np.random.randn(n_in_W2, n_out_W2) * std_dev_W2
    b2 = np.zeros((1, n_out_W2))
```
Por que Xavier?
A inicializa√ß√£o de Xavier √© ideal para fun√ß√µes de ativa√ß√£o sim√©tricas como tanh. Ela visa manter a vari√¢ncia das ativa√ß√µes e gradientes relativamente constantes em cada camada, o que acelera a converg√™ncia e evita a satura√ß√£o ou o desvanecimento dos gradientes.

---

#### Forward Pass
```python
    # x √© a entrada na rede
    def forward(x):
        z1 = x @ W1 + b1
        ativ = tanh(z1)
        z2 = ativ @ W2 + b2
        y_pred = z2
        return y_pred, z1, ativ, z2
``` 
Aqui definimos a propaga√ß√£o direta (forward pass).
1. **z1** √© a combina√ß√£o linear entre entrada e pesos.
2. **ativ** aplica a fun√ß√£o tanh, como discutido, essencial para manter os valores entre -1 e 1.
3. **z2** combina as ativa√ß√µes da camada oculta com os pesos para gerar a predi√ß√£o y_pred.

---

#### Backpropagation
``` python
def backprop(current_lr):
    global W1, b1, W2, b2

    # Gradiente para W2 e b2
    dW2 = ativ.T @ d_loss_y_pred(y_pred, y_true)
    db2 = np.sum(d_loss_y_pred(y_pred, y_true), axis=0, keepdims=True)

    # Propaga√ß√£o do erro para a camada oculta
    d_ativ = d_loss_y_pred(y_pred, y_true) @ W2.T

    # Gradiente da camada oculta com derivada da tanh
    delta1 = d_ativ * tanh_derivate(z1)

    # Gradientes para W1 e b1
    dW1 = x.T @ delta1
    db1 = np.sum(delta1, axis=0, keepdims=True)

    # Atualiza√ß√£o dos pesos
    W2 -= current_lr * dW2
    b2 -= current_lr * db2
    W1 -= current_lr * dW1
    b1 -= current_lr * db1
```
A fun√ß√£o ```backprop(current_lr)```  implementa a retropropaga√ß√£o, ou seja, o c√°lculo dos gradientes da fun√ß√£o de perda em rela√ß√£o aos pesos da rede, e a atualiza√ß√£o desses pesos para minimizar o erro.

##### Etapas detalhadas:
1. Gradientes da camada de sa√≠da (W2 e b2):
```python
dW2 = ativ.T @ d_loss_y_pred(y_pred, y_true)
db2 = np.sum(d_loss_y_pred(y_pred, y_true), axis=0, keepdims=True)
```
- O gradiente da perda em rela√ß√£o aos pesos W2 depende das ativa√ß√µes da camada oculta (ativ) e do gradiente da perda em rela√ß√£o √† predi√ß√£o (d_loss_y_pred).
- A derivada em rela√ß√£o ao vi√©s b2 √© a soma desse gradiente ao longo do batch.
- Aqui usamos produto matricial para calcular tudo de forma vetorizada.

2. Propaga√ß√£o do erro para a camada oculta:
``` python
d_ativ = d_loss_y_pred(y_pred, y_true) @ W2.T
```
- Esse √© o erro transmitido para tr√°s da camada de sa√≠da para a oculta.
- Multiplicamos o gradiente da perda pelo peso da sa√≠da (W2), usando transposta para manter as dimens√µes corretas.
- Isso aplica a regra da cadeia entre as camadas.

3. Gradiente da camada oculta (aplicando a derivada da tanh):
```python
delta1 = d_ativ * tanh_derivate(z1)
```
- A propaga√ß√£o do erro passa pela fun√ß√£o de ativa√ß√£o: precisamos multiplicar pelo gradiente da tanh (derivada).
- Aqui, tanh_derivate(z1) d√° a sensibilidade da camada oculta em rela√ß√£o √† sua entrada z1.
- Resultado: delta1 ‚Üí como ajustar a camada oculta para reduzir o erro.

4. Gradientes dos pesos e vi√©s da camada oculta (W1 e b1):
```python
dW1 = x.T @ delta1
db1 = np.sum(delta1, axis=0, keepdims=True)
```
- Igual √† camada de sa√≠da: produto das entradas x pela propaga√ß√£o de erro delta1.
- Vi√©s √© a soma dos deltas ao longo do batch.

5. Atualiza√ß√£o dos pesos (descida do gradiente):
``` python
W2 -= current_lr * dW2
b2 -= current_lr * db2
W1 -= current_lr * dW1
b1 -= current_lr * db1
```
- Finalmente, ajustamos cada peso e vi√©s na dire√ß√£o oposta ao gradiente para reduzir o erro.
- A taxa de aprendizado (current_lr) controla o tamanho do ajuste.

---

#### Loop de Treinamento
``` python
    batch_size = 64
    initial_lr = 0.01
    current_lr = initial_lr
    decay_rate = 0.999995
    summing_loss = 0
    mean_loss_atual = 1
    mean_loss_anterior = 1
    gaap_view = 500
    loss_history = []
    tolerancia = 1e-6
    fine_tuning_multiplier = 1
```
O que significa cada coisa?

- batch_size = 64 ‚Üí Quantidade de exemplos que o modelo v√™ por itera√ß√£o. Isso √© chamado de "batch": evita treinar com um √∫nico exemplo ou o dataset inteiro. D√° equil√≠brio entre estabilidade e velocidade.
- initial_lr = 0.08 ‚Üí Taxa de aprendizado inicial ‚Äî define o tamanho dos passos na atualiza√ß√£o dos pesos.
- current_lr = initial_lr ‚Üí Come√ßa igual ao inicial, mas vai diminuindo com o tempo.
- decay_rate = 0.999995 ‚Üí Fator que faz o learning rate decrescer a cada √©poca.
- summing_loss = 0 ‚Üí Acumulador para somar as perdas dentro de um intervalo (gaap_view).
- mean_loss_atual e mean_loss_anterior ‚Üí Guardam as m√©dias da perda atual e anterior.
- gaap_view = 500 ‚Üí Intervalo de √©pocas entre os prints e o c√°lculo da m√©dia de perda.
- loss_history = [] ‚Üí Guarda o hist√≥rico das m√©dias de perda ao longo do treinamento.
- tolerancia = 1e-7 ‚Üí O quanto √© considerado estagnado para a aprendizagem da rede
- fine_tuning_multiplier = 1 ‚Üí Usado para atualizar o valor do current_lr

```python
    for epoch in range(1_000_000):
```

1. Decaimento da taxa de aprendizado:

```python
 if current_lr > 0.000001 :
    current_lr = initial_lr * (decay_rate ** epoch) * fine_tuning_multiplier
```

A cada √©poca, a current_lr diminui exponencialmente, um passo muito grande inpede de entrar cada vez mais no vale, um passo curto demais levar√° milhares de √©pocas para fazer progresso. A l√≥gica √© come√ßar com um passo maior e quanto mais perto do vale (o m√≠nimo local da fun√ß√£o de perda) menor ser o passo para darmos um passos cada mais vez mais precisos, esse *preciosismo* √© chamdo de Fine Tunning.
Esse decaimento √© combinado com o fine_tuning_multiplier:
‚Üí Se o modelo parece estagnado, o multiplicador aumenta, elevando novamente o learning rate e permitindo escapar de m√≠nimos locais.
‚Üí Se n√£o h√° estagna√ß√£o, o multiplicador mant√©m o decaimento padr√£o.

2. Cria√ß√£o do batch:
```python
x = np.random.uniform(-np.pi, np.pi, size=(batch_size, 1))
y_true = np.sin(x)
```

Um batch de 64 valores aleat√≥rios entre -œÄ e œÄ.  
y_true √© o resultado esperado.

3. Forward pass:
```python
y_pred, z1, ativ, z2 = forward(x)
```
O modelo gera uma predi√ß√£o (y_pred) e tamb√©m os valores intermedi√°rios usados no backpropagation.

4. C√°lculo do erro e ac√∫mulo:
```python
error = loss_fn(y_pred, y_true)
summing_loss += error
```
Calcula o erro deste batch e acumula para depois fazer a m√©dia.

5. Backpropagation:
```python
backprop(current_lr)
```
Ajusta os pesos de acordo com o erro calculado e a taxa de aprendizado atual.

6. Monitoramento e impress√£o:
```python
if epoch % gaap_view == 0:
    mean_loss_atual = summing_loss / gaap_view
    summing_loss = 0
    print(f"Epoch {epoch}, Mean loss: {mean_loss_atual:.8f}, Lr: {current_lr:.8f}")
    loss_history.append(mean_loss_atual)
    mean_loss_anterior = mean_loss_atual
```
A cada gaap_view √©pocas (500):
- Calcula a m√©dia da perda.
- Zera o acumulador.
- Imprime a √©poca atual, a perda m√©dia e o learning rate.
- Guarda a m√©dia no hist√≥rico de perdas (loss_history) e tamb√©m o hist√≥rico da taxa de aprendizado (lr_history).

7. Crit√©rio adaptativo de ajuste fino:
``` python
    last_loss = loss_history[-10:]
    dif_max = max(last_loss) - min(last_loss)

    if dif_max < tolerancia:
        fine_tuning_multiplier = 1.3
        print("aumentou o lr rate")
    else: 
        fine_tuning_multiplier = 1
```
Se a diferen√ßa m√°xima entre os √∫ltimos 10 valores da perda for menor que a toler√¢ncia, considera que a perda estagnou e aumenta o fine_tuning_multiplier para 1.3, elevando o learning rate para tentar escapar de m√≠nimos locais.

Caso contr√°rio, mant√©m o multiplicador neutro (1), deixando o decaimento suave e progressivo.

8. Crit√©rio de parada:
```python
if epoch > 10 and mean_loss_atual < 0.0000006:
    print(f"Convergiu na epoch {epoch} com Loss {mean_loss_atual:8f} ")
    break
```
Se ap√≥s pelo menos 10 √©pocas a perda for muito pequena, considera que o modelo convergiu e interrompe o treinamento.

---

#### Avalia√ß√£o no Conjunto de Teste
```python
    x_test = np.linspace(-np.pi, np.pi, 100).reshape(-1, 1)
    y_true = np.sin(x_test)
    y_pred, *_ = forward(x_test)

    error = loss_fn(y_pred, y_true)
    print(f"Erro de teste: {error}")
```
Depois de treinar, realizamos uma avalia√ß√£o no conjunto de teste para verificar a generaliza√ß√£o da rede.

---

#### Visualiza√ß√£o da perda em rela√ß√£o √† taxa de aprendizagem 
```python
    plt.figure(figsize=(12, 7)) 

    # Eixo Y para a Perda
    ax1 = plt.gca() 
    ax1.plot(range(0, len(loss_history)*gaap_view, gaap_view), loss_history, label='Mean Loss', color='blue')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Mean Loss', color='blue')
    ax1.tick_params(axis='y', labelcolor='blue')
    ax1.set_yscale('log') 
    ax1.grid(True)

    # Eixo Y para a Taxa de Aprendizado (current_lr)
    ax2 = ax1.twinx()
    ax2.plot(range(0, len(lr_history)*gaap_view, gaap_view), lr_history, label='Learning Rate', color='red', linestyle='--')
    ax2.set_ylabel('Learning Rate', color='red')
    ax2.tick_params(axis='y', labelcolor='red')
    ax2.set_yscale('log') 

    plt.title('Evolu√ß√£o da Fun√ß√£o de Perda e Learning Rate')

    # Combinar as legendas dos dois eixos
    lines, labels = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines + lines2, labels + labels2, loc='upper right')


    plt.show()
```
Curva azul (Mean Loss):
- Normalmente come√ßa com valores altos e, conforme o treinamento avan√ßa, deve cair rapidamente no in√≠cio e depois mais lentamente, at√© estabilizar.
- O uso da escala logar√≠tmica permite visualizar claramente tanto as grandes perdas iniciais quanto os pequenos ajustes finais.

Curva vermelha tracejada (Learning Rate):
- Mostra a diminui√ß√£o programada e adaptativa da taxa de aprendizado.
- Quedas abruptas ou pequenos aumentos podem indicar ajustes finos feitos automaticamente com base na detec√ß√£o de estagna√ß√£o (quando a perda varia muito pouco).
- Se a linha da perda come√ßa a estabilizar, a taxa de aprendizado provavelmente foi reduzida para permitir um fine tuning mais preciso.

**Padr√µes importantes de observar:**

- Quando a Learning Rate cai, a curva de Mean Loss tende a estabilizar ou diminuir mais suavemente.
- Se a Mean Loss n√£o melhora mais ou flutua muito pouco, o ajuste autom√°tico do fine_tuning_multiplier pode ter aumentado temporariamente a learning rate para tentar escapar de um plat√¥.
- A converg√™ncia ocorre quando a Mean Loss atinge valores muito baixos e est√°veis.
- Quedas bruscas na learning rate costumam indicar que o modelo entrou em uma fase de ajuste mais fino.
- Estagna√ß√µes na Mean Loss podem sinalizar que o modelo atingiu um limite de capacidade ou que a taxa de aprendizado ficou muito baixa.
- Se a Mean Loss cai suavemente e depois estabiliza pr√≥xima a zero, o modelo convergiu corretamente.



---

#### Visualiza√ß√£o da Evolu√ß√£o da Fun√ß√£o de Perda
```python
    plt.figure(figsize=(10, 6))
    plt.plot(range(0, len(loss_history)*500, 500), loss_history, label='Mean Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Mean Loss')
    plt.title('Evolu√ß√£o da Fun√ß√£o de Perda')
    plt.yscale('log')
    plt.grid(True)
    plt.legend()
    plt.show()
```
Fixamos o y_true em 0.5 para gerar um gr√°fico 2D da fun√ß√£o de perda e ajudar a visualizar a l√≥gica da busca pelo m√≠nimo local. O ponto idel para o y_pred √© o ponto vermelho, usando de gradiente linear buscamos, ao inicar em qualquer parte do gr√°fico alcan√ßar o √≥timo local indicado pelo ponto vermelho no vale da curva.

---

#### Superf√≠cie da Fun√ß√£o de Perda - 3D
```python
    # Fixe um conjunto de entrada para o teste
    x_test = np.linspace(-np.pi, np.pi, 100).reshape(-1, 1)
    y_test = np.sin(x_test)

    w1_range = np.linspace(-5, 5, 50)
    w2_range = np.linspace(-5, 5, 50)

    loss_surface = np.zeros((len(w1_range), len(w2_range)))

    original_w1 = W1[0, 0]
    original_w2 = W2[0, 0]

    for i, w1_val in enumerate(w1_range):
        for j, w2_val in enumerate(w2_range):
            W1[0, 0] = w1_val
            W2[0, 0] = w2_val

            y_pred, *_ = forward(x_test)
            loss_surface[i, j] = loss_fn(y_pred, y_test)

    W1[0, 0] = original_w1
    W2[0, 0] = original_w2

    W1, W2 = np.meshgrid(w1_range, w2_range)

    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111, projection='3d')
    surf = ax.plot_surface(W1, W2, loss_surface.T, cmap='viridis')

    ax.set_xlabel('Peso w1[0,0]')
    ax.set_ylabel('Peso w2[0,0]')
    ax.set_zlabel('Loss')

    plt.title('Paisagem da Fun√ß√£o de Perda')
    plt.show()
```
Esse gr√°fico permite visualizar a paisagem da fun√ß√£o de perda, mostrando como diferentes valores de pesos afetam o erro.
Important√≠ssimo para entender o conceito de m√≠nimos locais e globais e sua influ√™ncia no aprendizado.

---

#### Visualiza√ß√£o 3D com Plotly

```python
    fig = go.Figure(data=[go.Surface(z=loss_surface.T, x=W1, y=W2, colorscale='Viridis')])

    fig.update_layout(
        title='Paisagem da Fun√ß√£o de Perda',
        scene = dict(
            xaxis_title='Peso w1[0,0]',
            yaxis_title='Peso w2[0,0]',
            zaxis_title='Loss'
        )
    )

    fig.show()
```

Esse comando cria um gr√°fico 3D que mostra como a **fun√ß√£o de perda** (loss) varia de acordo com dois pesos do modelo:  
- W1 ‚Üí eixo X  
- W2 ‚Üí eixo Y  
- Loss ‚Üí eixo Z (altura)  

Ou seja: cada ponto na superf√≠cie mostra o valor da perda (erro) para uma determinada combina√ß√£o dos pesos W1[0,0] e W2[0,0].


- A fun√ß√£o de perda cria uma esp√©cie de **"paisagem"**, com vales e montanhas.
- O modelo quer encontrar o **ponto mais baixo dessa paisagem** ‚Äî onde a perda √© m√≠nima.
- O **gradiente descendente** √© o m√©todo que move os pesos nessa superf√≠cie sempre na dire√ß√£o onde a perda diminui mais rapidamente.

**Como?**  
1. Calcula o gradiente ‚Üí dire√ß√£o de maior subida.  
2. Move na dire√ß√£o oposta ‚Üí descida mais r√°pida.  
3. Repete at√© chegar no "vale" ‚Üí m√≠nimo da fun√ß√£o.

Por isso se chama "descendente": sempre descendo na paisagem da perda.


- A superf√≠cie 3D mostra a forma da fun√ß√£o de perda em rela√ß√£o aos pesos.
- Locais altos ‚Üí alta perda ‚Üí m√°s escolhas de pesos.
- Locais baixos ‚Üí baixa perda ‚Üí boas escolhas de pesos.
- O modelo quer mover os pesos at√© chegar numa dessas regi√µes baixas.

---

#### Predi√ß√µes Aleat√≥rias
``` python  
    num_tests = 10

    for _ in range(num_tests):
        valor = np.random.uniform(-np.pi, np.pi, size=(1, 1))
        x = np.array(valor)
        y_pred, _, _, _ = forward(x)

        print(f"input: {valor[0][0]:.4f}")
        print(f"Predi√ß√£o: {y_pred[0][0]:.4f}")
        print(f"sin({valor[0][0]:.4f}): {np.sin(valor)[0][0]:.4f}")
        print("-" * 20)
```
Esse √© o Teste Final: comparamos predi√ß√µes da rede para entradas aleat√≥rias com o valor real de sin(x). Isso evidencia a capacidade da rede em aprender a fun√ß√£o alvo.

---

üòÄ Incr√≠vel n√© !? Aparentemente n√£o precisa de m√°gica pra funcionar

---

#### Referencias
- <a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" target="_blank">3Blue1Brown</a>
- IA, porque ningu√©m merece debugar sozinho 